export default {
  nav: {
    dashboard: 'Dashboard',
    models: 'Models',
    chat: 'Chat',
    settings: 'Settings',
    appName: 'Llama Dashboard',
  },
  common: {
    online: 'Online',
    offline: 'Offline',
    loading: 'Loading...',
    error: 'Error',
    confirm: 'Confirm',
    cancel: 'Cancel',
    save: 'Save',
    delete: 'Delete',
    back: 'Back',
    search: 'Search',
    noData: 'No data',
  },
  dashboard: {
    title: 'Dashboard',
    subtitle: 'System overview and quick actions',
    modelsLoaded: 'Models Loaded',
    modelsAvailable: 'Models Available',
    serverStatus: 'Server Status',
    conversations: 'Conversations',
    quickActions: 'Quick Actions',
    startChat: 'Start Chat',
    startChatDesc: 'Open a new conversation',
    manageModels: 'Manage Models',
    manageModelsDesc: 'Load, unload, and configure models',
    rescanModels: 'Rescan Models',
    rescanModelsDesc: 'Scan directories for new models',
    settingsAction: 'Settings',
    settingsDesc: 'Configure directories and API',
    loadedModels: 'Loaded Models',
    unload: 'Unload',
    chat: 'Chat',
  },
  models: {
    title: 'Models',
    subtitle: 'Manage your local GGUF models',
    rescan: 'Rescan',
    searchPlaceholder: 'Search models...',
    allStatus: 'All Status',
    loaded: 'Loaded',
    unloaded: 'Unloaded',
    loadingStatus: 'Loading',
    errorStatus: 'Error',
    gridView: 'Grid view',
    tableView: 'Table view',
    load: 'Load',
    unload: 'Unload',
    chat: 'Chat',
    favorite: 'Favorite',
    unfavorite: 'Unfavorite',
    loadModel: 'Load Model',
    contextSize: 'Context Size',
    gpuLayers: 'GPU Layers (-1 = auto)',
    emptyState: 'No models found. Add model directories in {link} and rescan.',
    settingsLink: 'Settings',
    name: 'Name',
    architecture: 'Architecture',
    quantization: 'Quantization',
    size: 'Size',
    context: 'Context',
    status: 'Status',
    actions: 'Actions',
  },
  modelDetail: {
    backToModels: 'Back to Models',
    modelInfo: 'Model Information',
    actions: 'Actions',
    id: 'ID',
    architecture: 'Architecture',
    quantization: 'Quantization',
    fileSize: 'File Size',
    contextLength: 'Context Length',
    parameters: 'Parameters',
    status: 'Status',
    openChat: 'Open Chat',
    unloadModel: 'Unload Model',
    loadModel: 'Load Model',
    contextSize: 'Context Size',
    gpuLayers: 'GPU Layers (-1 = auto)',
    chatTemplate: 'Chat Template',
    unknown: 'Unknown',
  },
  chat: {
    newChat: '+ New Chat',
    noConversation: 'Start a conversation',
    selectModelPrompt: 'Select a loaded model and begin chatting',
    noModels: 'No models loaded.',
    loadModelLink: 'Load a model',
    loadModelSuffix: ' first.',
    typeMessage: 'Type a message... (Shift+Enter for new line)',
    send: 'Send',
    stop: 'Stop',
    generating: 'Generating...',
    temperature: 'Temperature',
    maxTokens: 'Max Tokens',
    topP: 'Top P',
    systemPrompt: 'System Prompt',
    systemPromptPlaceholder: 'You are a helpful assistant.',
    params: 'Parameters',
    deleteConv: 'Delete',
  },
  settings: {
    title: 'Settings',
    subtitle: 'Configure your Llama Dashboard',
    modelDirs: 'Model Directories',
    addDir: 'Add Directory',
    addDirPlaceholder: 'Enter directory path...',
    remove: 'Remove',
    defaultParams: 'Default Inference Parameters',
    ctxSize: 'Context Size',
    gpuLayers: 'GPU Layers',
    temperature: 'Temperature',
    apiKey: 'API Key',
    apiKeyPlaceholder: 'Optional API key for authentication',
    appearance: 'Appearance',
    theme: 'Theme',
    light: 'Light',
    dark: 'Dark',
    language: 'Language',
    saveConfig: 'Save Configuration',
    saved: 'Configuration saved!',
    saveFailed: 'Failed to save configuration',
  },
}
